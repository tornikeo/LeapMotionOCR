{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tornikeo/Documents/uni/PRCV/proj\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_mnist, load_training_data\n",
    "\n",
    "d_x, d_y = load_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.92830</td>\n",
       "      <td>304.45</td>\n",
       "      <td>-18.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.14750</td>\n",
       "      <td>304.36</td>\n",
       "      <td>-18.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.86880</td>\n",
       "      <td>304.32</td>\n",
       "      <td>-18.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.69000</td>\n",
       "      <td>303.81</td>\n",
       "      <td>-19.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.82100</td>\n",
       "      <td>302.69</td>\n",
       "      <td>-19.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-19.58500</td>\n",
       "      <td>300.62</td>\n",
       "      <td>-19.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-25.51100</td>\n",
       "      <td>295.96</td>\n",
       "      <td>-19.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-31.59000</td>\n",
       "      <td>287.91</td>\n",
       "      <td>-18.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-36.29700</td>\n",
       "      <td>275.38</td>\n",
       "      <td>-19.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-37.79700</td>\n",
       "      <td>264.15</td>\n",
       "      <td>-18.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-37.07000</td>\n",
       "      <td>252.71</td>\n",
       "      <td>-17.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-35.45700</td>\n",
       "      <td>244.30</td>\n",
       "      <td>-17.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-31.16200</td>\n",
       "      <td>231.87</td>\n",
       "      <td>-17.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-25.45800</td>\n",
       "      <td>221.83</td>\n",
       "      <td>-17.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-18.21400</td>\n",
       "      <td>215.30</td>\n",
       "      <td>-17.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-9.02520</td>\n",
       "      <td>212.38</td>\n",
       "      <td>-18.352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.01657</td>\n",
       "      <td>211.87</td>\n",
       "      <td>-19.287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.07060</td>\n",
       "      <td>215.86</td>\n",
       "      <td>-20.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15.80700</td>\n",
       "      <td>221.91</td>\n",
       "      <td>-22.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.26800</td>\n",
       "      <td>231.92</td>\n",
       "      <td>-22.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.85600</td>\n",
       "      <td>244.28</td>\n",
       "      <td>-22.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>19.54900</td>\n",
       "      <td>258.00</td>\n",
       "      <td>-22.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.75400</td>\n",
       "      <td>270.96</td>\n",
       "      <td>-20.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.48420</td>\n",
       "      <td>283.29</td>\n",
       "      <td>-20.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.65800</td>\n",
       "      <td>291.08</td>\n",
       "      <td>-19.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-3.75220</td>\n",
       "      <td>298.97</td>\n",
       "      <td>-19.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-9.98550</td>\n",
       "      <td>303.88</td>\n",
       "      <td>-18.656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-14.71800</td>\n",
       "      <td>306.53</td>\n",
       "      <td>-18.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-16.99900</td>\n",
       "      <td>306.99</td>\n",
       "      <td>-18.273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-17.88200</td>\n",
       "      <td>306.96</td>\n",
       "      <td>-18.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-18.14000</td>\n",
       "      <td>306.52</td>\n",
       "      <td>-18.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-18.08300</td>\n",
       "      <td>305.79</td>\n",
       "      <td>-18.846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1       2\n",
       "0   -8.92830  304.45 -18.469\n",
       "1   -9.14750  304.36 -18.585\n",
       "2   -9.86880  304.32 -18.896\n",
       "3  -11.69000  303.81 -19.305\n",
       "4  -14.82100  302.69 -19.284\n",
       "5  -19.58500  300.62 -19.579\n",
       "6  -25.51100  295.96 -19.006\n",
       "7  -31.59000  287.91 -18.021\n",
       "8  -36.29700  275.38 -19.003\n",
       "9  -37.79700  264.15 -18.385\n",
       "10 -37.07000  252.71 -17.931\n",
       "11 -35.45700  244.30 -17.759\n",
       "12 -31.16200  231.87 -17.103\n",
       "13 -25.45800  221.83 -17.138\n",
       "14 -18.21400  215.30 -17.494\n",
       "15  -9.02520  212.38 -18.352\n",
       "16  -0.01657  211.87 -19.287\n",
       "17   9.07060  215.86 -20.883\n",
       "18  15.80700  221.91 -22.263\n",
       "19  20.26800  231.92 -22.562\n",
       "20  21.85600  244.28 -22.473\n",
       "21  19.54900  258.00 -22.412\n",
       "22  14.75400  270.96 -20.791\n",
       "23   8.48420  283.29 -20.015\n",
       "24   3.65800  291.08 -19.836\n",
       "25  -3.75220  298.97 -19.403\n",
       "26  -9.98550  303.88 -18.656\n",
       "27 -14.71800  306.53 -18.428\n",
       "28 -16.99900  306.99 -18.273\n",
       "29 -17.88200  306.96 -18.303\n",
       "30 -18.14000  306.52 -18.437\n",
       "31 -18.08300  305.79 -18.846"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [00:14<00:00, 4725.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import rescale,resize\n",
    "from skimage.morphology import erosion, skeletonize\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.filters import gaussian\n",
    "from skimage.restoration import richardson_lucy, deconvolution\n",
    "from tqdm import tqdm\n",
    "\n",
    "mx_x = []\n",
    "for x in tqdm(m_x):\n",
    "    # x = erosion(x)\n",
    "    # x = rescale(x,2)\n",
    "    x = resize(x,(64,64))\n",
    "    mx_x.append(x)\n",
    "mx_x = np.stack(mx_x)\n",
    "    # psf = np.ones((7,7))/49\n",
    "    # x = richardson_lucy(x, psf, num_iter=10)\n",
    "    # x = unsharp_mask(x, radius=1, amount=1)\n",
    "    # x = deconvolution.\n",
    "    # x = skeletonize(x)\n",
    "    # x = gaussian(x)\n",
    "    # show(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_x = mx_x.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_rasterized_data, show\n",
    "\n",
    "data_x, data_y = load_rasterized_data(size=64, pad=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 64, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(data_x[0])\n",
    "show(data_x[-1])\n",
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import torch\n",
    "\n",
    "# Split the LM data into 50/50\n",
    "# Add MNIST to training half, test with only LM held-out dataset.\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data_x, \n",
    "    data_y, \n",
    "    test_size=0.50, \n",
    "    shuffle=True,\n",
    "    stratify=data_y,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = np.concatenate((mx_x, x_train)) \n",
    "y_train = np.concatenate((m_y, y_train))\n",
    "\n",
    "# x_train = x_train.reshape(len(x_train), -1)\n",
    "# x_test = x_test.reshape(len(x_test), -1)\n",
    "\n",
    "x_train = torch.tensor(x_train).float().unsqueeze(1)\n",
    "x_train_lm = x_train[-500:]\n",
    "x_test = torch.tensor(x_test).float().unsqueeze(1)\n",
    "\n",
    "y_train = torch.tensor(y_train)\n",
    "y_train_lm = y_train[-500:]\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST LOSS 0.14700093865394592538\n",
      "LeapMotion LOSS 0.016503222286701202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.96      0.96      0.96        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.96      0.96      0.96        50\n",
      "           9       0.96      0.94      0.95        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  0  0 48  0]\n",
      " [ 0  0  0  0  2  0  0  0  1 47]]\n",
      "LeapMotion LOSS 0.0065168035216629505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.96      0.96      0.96        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.96      0.97        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  0  0 48  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0035664353054016835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0023098343517631292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0016570062143728137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0012738334480673075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0010240991832688458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0008504851721227169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0007233566138893366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n",
      "LeapMotion LOSS 0.0006262263632379472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        50\n",
      "           1       0.94      0.90      0.92        50\n",
      "           2       0.94      1.00      0.97        50\n",
      "           3       1.00      1.00      1.00        50\n",
      "           4       0.96      0.94      0.95        50\n",
      "           5       0.98      0.98      0.98        50\n",
      "           6       0.94      0.96      0.95        50\n",
      "           7       0.94      0.96      0.95        50\n",
      "           8       0.98      0.94      0.96        50\n",
      "           9       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.96       500\n",
      "   macro avg       0.96      0.96      0.96       500\n",
      "weighted avg       0.96      0.96      0.96       500\n",
      "\n",
      "[[48  0  0  0  0  1  1  0  0  0]\n",
      " [ 0 45  1  0  0  0  0  3  1  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 50  0  0  0  0  0  0]\n",
      " [ 1  0  0  0 47  0  0  0  0  2]\n",
      " [ 0  0  0  0  0 49  1  0  0  0]\n",
      " [ 1  1  0  0  0  0 48  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 48  0  0]\n",
      " [ 0  0  2  0  0  0  1  0 47  0]\n",
      " [ 0  0  0  0  2  0  0  0  0 48]]\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torch.nn import functional as F\n",
    "\n",
    "train_ds = data.TensorDataset(x_train, y_train)\n",
    "test_ds = data.TensorDataset(x_test, y_test)\n",
    "\n",
    "train_dl = data.DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dl = data.DataLoader(test_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "# train_main_dl\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cnn_block = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, (3, 3),),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(8, 32, (3, 3)),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(32, 64, (3, 3)),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 128, (3, 3)),\n",
    "            nn.AvgPool2d(4),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # self.bn = nn.BatchNorm2d(32)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.ff = nn.Linear(128, 100)\n",
    "        self.out = nn.Linear(100, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_block(x)\n",
    "        \n",
    "        x = self.flat(x)\n",
    "        # print(x.shape)\n",
    "        x = F.leaky_relu(self.ff(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Net()\n",
    "optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.9)\n",
    "model.to(device)\n",
    "\n",
    "for ep in range(10):\n",
    "    for bn, (xb, yb) in enumerate(train_dl):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        ll = model(xb)\n",
    "        loss = F.nll_loss(F.log_softmax(ll, dim=1), yb)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "    print(\"MNIST LOSS\", loss.item(), end='\\r')\n",
    "print()\n",
    "\n",
    "for _ in range(10): \n",
    "    optim = torch.optim.SGD(model.parameters(), lr=0.01, momentum=.9)\n",
    "    x_train_lm = x_train_lm.to(device)\n",
    "    y_train_lm = y_train_lm.to(device)\n",
    "    for _ in range(100):\n",
    "        ll = model(x_train_lm)\n",
    "        loss = F.nll_loss(F.log_softmax(ll, dim=1), y_train_lm)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        # We are only interested in loss over LM data\n",
    "        print(\"LeapMotion LOSS\", loss.item(), end='\\r')\n",
    "    print()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        \n",
    "        ll = model(x_test)\n",
    "        proba = F.log_softmax(ll, dim=1)\n",
    "        loss = F.nll_loss(proba, y_test)\n",
    "        predicted = proba.argmax(-1)\n",
    "        \n",
    "        print(classification_report(y_test.cpu(), predicted.cpu()))\n",
    "        print(confusion_matrix(y_test.cpu(), predicted.cpu()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
